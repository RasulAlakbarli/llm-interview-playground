A practice repo for building language models from scratch (n-gram → MLP → Transformer) on a quotes dataset, as preparation for LLM / ML research interviews.

The goal is to re-implement the core pieces you might be asked to code live:
- Data pipeline for text
- N-gram language model
- Simple neural LM (MLP)
- Mini Transformer / GPT-style model in PyTorch
